\documentclass[10pt]{article}
\setlength{\parskip}{0.25\baselineskip}
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb, graphicx, multicol, array}
\usepackage[font=small,labelfont=bf]{caption}
\usepackage{float}
\usepackage{bbm}
\usepackage{dsfont}
\newcommand{\supp}{{\text{supp}}} 
\newcommand{\bv}{{\text{BV}}}
\newcommand{\ac}{{\text{AC}}}
\newcommand{\vol}{{\text{Vol}}}


\ExplSyntaxOn
\NewDocumentCommand{\cycle}{ O{\;} m }
 {
  (
  \alec_cycle:nn { #1 } { #2 }
  )
 }

\seq_new:N \l_alec_cycle_seq
\cs_new_protected:Npn \alec_cycle:nn #1 #2
 {
  \seq_set_split:Nnn \l_alec_cycle_seq { , } { #2 }
  \seq_use:Nn \l_alec_cycle_seq { #1 }
 }
\ExplSyntaxOff

\newenvironment{problem}[2][]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\begin{document}
 
\title{Homework \#5}
\author{Eric Tao\\
Math 285: Homework \#5}
\maketitle

\begin{problem}{Question 1}

Consider the solution set of the following system of equations in an ambient $\mathbb{R}^3$:

$$ x^3 + y^3 + z^3 = 1, \quad z = xy $$

Is this a smooth manifold?

\end{problem}

\begin{proof}[Solution]

Call the solution set of these simultaneous equations $S$. 

We may define the function $F: \mathbb{R}^3 \to \mathbb{R}^2$ via

$$ F(x,y,z) = (x^3 + y^3 + z^3, z - xy) $$

Then, of course, $S$ is the level set $F^{-1}(1,0)$. Naming the first equation $f$, and the second equation $g$, we may write out the Jacobian matrix of $F$ as:

$$ J(F) = \begin{bmatrix} f_x & f_y& f_z \\ g_x & g_y & g_z \end{bmatrix} = \begin{bmatrix} 3x^2 & 3y^2& 3z^2 \\ -y & -x & 1 \end{bmatrix} $$

Then, critical points of $F$ are exactly points where $J(F)$ has rank less than $2$. Equivalently, then, we require the determinant of every $2 \times 2$ minor to vanish:

$$ \begin{cases} \left| \begin{array}{cc} 3x^2 & 3y^2 \\ -y & -x \end{array} \right| = -3x^3 + 3y^3 \\ \\ \left| \begin{array}{cc} 3x^2 & 3z^2 \\ -y & 1 \end{array} \right| = 3x^2 + 3z^2y \\ \\  \left| \begin{array}{cc} 3y^2 & 3z^2 \\ -x & 1 \end{array} \right| = 3y^2 + 3z^2x \end{cases}$$

Setting the first equation to 0, we can see that in the reals:

$$ -3x^3 + 3y^3  = 0 \implies y^3 - x^3 = 0 \implies (y-x)(y^2 + xy + x^2) = 0 \implies y = x$$

as $y^2 + xy + x^2 = 0$ has the only solution $x = y = 0$ in the reals. 

Then, using the second equation, and using $x = y$:

$$  3x^2 + 3z^2y = 0 \implies 3x(x + z^2) = 0 \implies x = 0 \text{ or } x = -z^2 $$

Suppose $x = 0$. Then, we have that $y = 0$. From $f$, then, we have that $0^3 + 0^3 + z^3 = 1 \implies z = 1$. However, $g(0,0,1)  = 1 - 0*0 = 1 \not = 0$. So we have no critical points in $S$ in this case.

Now, suppose $x = y = -z^2$. Then, we have that $g(-z^2, -z^2, z) = z - (-z^2)(-z^2) = z(1-z^3) = 0 \implies z = 0, 1$ since, again, the only real cube root of unity is $1$. However, $f(0,0,0)  = 0 \not = 1$ and $f(-1,-1,1) = (-1)^3 + (-1)^3 + 1^3 = -1 \not = 1$. Therefore, we have no critical points in $S$ in this case either.

Thus, we can conclude that $S$ contains no critical points of $F$. Therefore, $S$ is a regular level set, and by the regular level set theorem, $S$ is a regular submanifold of $\mathbb{R}^3$ with dimension 1. Thus, $S$ is a smooth manifold.

\end{proof}

\begin{problem}{Question 2}

We call a polynomial $F(x_0,...,x_n) \in \mathbb{R}[x_0,...,x_n]$ homogeneous of degree $k$ if it is a linear combination of monomials $x_0^{q_0}...x_n^{q_n}$, with $\sum_{j=0}^n q_j = k$. 

Prove that for any homogeneous polynomial $F(x_0,...,x_n)$ with degree $k$, that:

$$ \sum_{i=0}^n x_i \frac{\partial F}{\partial x_i} = kF $$

\end{problem}

\begin{proof}[Solution]

Fix a degree $k$. Due to the linearity of partial derivatives, we need only show this to be true for $F$ a monomial. So, let $F = x_0^{q_0}...x_n^{q_n}$ such that $\sum_{j=0}^n q_j = k$.

Computing via the power rule, we notice that:

$$ \begin{cases} x_i \frac{\partial}{\partial x_i} x_i^m = x_i * m x_i^{m-1} = mx_i^m & \text{ for } m \not = 0 \\  x_i \frac{\partial}{\partial x_i} 1 = x_i * 0 = 0 & \text{ for }m = 0 \end{cases}$$

Thus, we can say that:

$$x_i \frac{\partial}{\partial x_i} x_i^m = mx_i^m$$ since in the case $m = 0$, the product still vanishes.

Therefore, using this fact, we have that:

$$  \sum_{i=0}^n x_i \frac{\partial F}{\partial x_i} =  \sum_{i=0}^n  x_i \frac{\partial}{\partial x_i}( x_0^{q_0}...x_n^{q_n}) = \sum_{i=0}^n q_i x_0^{q_0}...x_n^{q_n} = \left( \sum_{i=0}^n q_i \right) F$$

But, by the definition of the degree, this is exactly $kF$ as desired. Since this is true for monomials, and because partial derivatives are linear, this is true for all linear combinations of monomials. Thus, this is true for any homogeneous polynomial of degree $k$.
 
$\mathfrak{Z}$
\end{proof}

\begin{problem}{Question 3}

Let $F = F(x_0,...,x_n)$ be a homogeneous polynomial on a real projective space $\mathbb{P}^n$.

Define a real projective variety as the zero set of finitely many homogeneous polynomials in $\mathbb{P}^n$. If there is exactly one polynomial of degree $k$, call the projective variety a hypersurface of degree $k$.

Show that the hypersurface $Z(F)$ with $F(x_0,x_1,x_2) = 0$  in $\mathbb{P}^3$ is smooth if $\partial F/ \partial x_0, \partial F/ \partial x_1, \partial F/ \partial x_2$ do not simultaneously vanish on $Z(F)$.

\end{problem}

\begin{proof}[Solution]

We will show the hypersurface is smooth by showing it as a regular submanifold on $\mathbb{P}^n$. Let $F = F(x_0,x_1,x_2)$ be a homogeneous polynomial of degree $k$, and let $Z(F)$ be its zero set in $\mathbb{P}^n$.

First, restrict ourselves to the standard open set $U_0 =  \{ (x_0, x_1, x_2 ) : x_0 \not = 0 \}$ equipped with the chart $\phi_0: U_0 \to \mathbb{R}^2$ via $(x_0, x_1, x_2) \mapsto (x_1/x_0, x_2/x_1)$.

We notice that on $U_0$, since $x_0$ never vanishes, we have that:

$$ F(x_0, x_1, x_2) = x_0^kF\left(1, \frac{x_1}{x_0}, \frac{x_2}{x_0}\right) = x_0^k F(1,x,y) $$

where we use the identification of the coordinates in $\mathbb{R}^2$ via $\phi_0$ as $x = x_1/x_0, y = x_2/x_0$. If we define $f(x,y) = F(1,x,y)$, then we have that $ x_0^k F(1,x,y) \iff F(1,x,y) = 0 \iff f(x,y) = 0$, where the first biconditional follows from $x_0 \not = 0$ by virtue of being on $U_0$, and the fact that $\mathbb{R}$ is a domain and the second biconditional is by definition.

Now, looking on this chart, we wish to look at the level set $f^{-1}(0)$. Of course, this is a $C^\infty$ map, as $f$ is a polynomial of $x,y$, being by definition, $F(1,x,y)$. Then, on this chart $(U, x = x_1/x_0, y = x_2/x_0)$, by 8.24, we have that $p \in U_0$ is a critical point if and only if:

$$ \frac{\partial f}{\partial x} (p) = 0 = \frac{\partial f}{\partial y}(p) $$

%Now, we can convert this back into derivatives of coordinates on $\mathbb{P}^2$, via $x = x_1/x_0, y = x_2/x_0$. We see that:

%\frac{\partial}{\partial x_0} =  \frac{\partial x}{\partial x_0}  \frac{\partial}{\partial x} +  \frac{\partial y}{\partial x_0}  \frac{\partial}{\partial y} = - \frac{x_1}{x_0^2} \frac{\partial}{\partial x} - \frac{x_2}{x_0^2} \frac{\partial}{\partial y} \\ 

%$$\begin{cases}  \frac{\partial}{\partial x_1} =  \frac{\partial x}{\partial x_1}  \frac{\partial}{\partial x} +  \frac{\partial y}{\partial x_1}  \frac{\partial}{\partial y} = \frac{1}{x_0} \frac{\partial}{\partial x} \\ \frac{\partial}{\partial x_2} =  \frac{\partial x}{\partial x_2}  \frac{\partial}{\partial x} +  \frac{\partial y}{\partial x_2}  \frac{\partial}{\partial y} = \frac{1}{x_0}\frac{\partial}{\partial y} \end{cases}$$

%Applying these onto $f$, we see that:

%\frac{\partial}{\partial x_0}(f) =  - \frac{x_1}{x_0^2} \frac{\partial f}{\partial x} - \frac{x_2}{x_0^2} \frac{\partial f}{\partial y} \\ 

%$$\begin{cases} \frac{\partial}{\partial x_1}(f) =  \frac{1}{x_0} \frac{\partial f}{\partial x} \\  \frac{\partial}{\partial x_2}(f) =  \frac{1}{x_0} \frac{\partial f}{\partial y} \end{cases} $$

%Then, since $\frac{1}{x_0} \not = 0$ for any $x_0$, we see that 

%$$ \frac{\partial f}{\partial x_1} =  \frac{\partial f}{\partial x_2} = 0 \iff \frac{\partial f}{\partial x}= \frac{\partial f}{\partial y} = 0 $$

Now, since $f(x,y) = F(1,x,y)$, then:

$$ \frac{\partial f}{\partial x}\bigg|_{p}= \frac{\partial f}{\partial y}\bigg|_{p} = 0 \iff \frac{\partial F}{\partial x}\bigg|_{p}= \frac{\partial F}{\partial y}\bigg|_{p} = 0$$

Since $x = x_1/x_0, y = x_2/x_0$, we may recompute these in terms of $x_0,x_1, x_2$:

$$\begin{cases}\frac{\partial}{\partial x_0} =  \frac{\partial x}{\partial x_0}  \frac{\partial}{\partial x} +  \frac{\partial y}{\partial x_0}  \frac{\partial}{\partial y} = - \frac{x_1}{x_0^2} \frac{\partial}{\partial x} - \frac{x_2}{x_0^2} \frac{\partial}{\partial y} \\   \frac{\partial}{\partial x_1} =  \frac{\partial x}{\partial x_1}  \frac{\partial}{\partial x} +  \frac{\partial y}{\partial x_1}  \frac{\partial}{\partial y} = \frac{1}{x_0} \frac{\partial}{\partial x} \\ \frac{\partial}{\partial x_2} =  \frac{\partial x}{\partial x_2}  \frac{\partial}{\partial x} +  \frac{\partial y}{\partial x_2}  \frac{\partial}{\partial y} = \frac{1}{x_0}\frac{\partial}{\partial y} \end{cases}$$

And, therefore:

$$\begin{cases} \frac{\partial}{\partial x_0}(F) =  - \frac{x_1}{x_0^2} \frac{\partial F}{\partial x} - \frac{x_2}{x_0^2} \frac{\partial F}{\partial y} \\  \frac{\partial}{\partial x_1}(F) =  \frac{1}{x_0} \frac{\partial F}{\partial x} \\  \frac{\partial}{\partial x_2}(F) =  \frac{1}{x_0} \frac{\partial F}{\partial y} \end{cases} $$

Thus, we have that:

$$ \frac{\partial F}{\partial x}\bigg|_{p}= \frac{\partial F}{\partial y}\bigg|_{p} = 0 \iff  \frac{\partial F}{\partial x_0}\bigg|_{p} =  \frac{\partial F}{\partial x_1}\bigg|_{p}= \frac{\partial F}{\partial x_2}\bigg|_{p} = 0$$

Therefore, if at least one of the $\frac{\partial F}{\partial x_0} \not = 0$, then we have that $f^{-1}(0)$ is a regular submanifold of $U_0$, by Theorem 9.7.

However, now we repeat this argument for $g(x,y) = F(x,1,y)$ on $U_1$, and $h(x,y) = F(x,y,1)$ on $U_2$. By the same argument, the zero sets of $g, h$ are regular submanifolds of $U_1, U_2$, respectively.

But here, we recall that on $U_0, U_1, U_2$, the zero set of $F$ aligns with $f, g, h$ respectively. Thus, using definition 9.1, the zero set of $F$ is a regular submanifold of dimension 1, because for any $p \in Z(F)$, we may $p$ belongs to at least one of $U_0, U_1, U_2$, say $U_0$, and there exists a chart in $U_0$, $V$, such that $Z(F) \cap V$ is defined by the vanishing of a coordinate. However, we notice that for $V$ to be open in $U_0$, by the subspace topology, it must come from an open set $\tilde{V} \cap U_0$. However, from the quotient topology, $U_0$ is open, and thus, if $V = \tilde{V} \cap U_0$, then $V$ itself is open in $\mathbb{P}^2$, being the finite intersection of open sets. Thus, we may take $V$ to be the neighborhood for $p$ in $\mathbb{P}^2$ such that $Z(F) \cap V$ is defined by the vanishing of a coordinate function. Since $U_0,U_1, U_2$ cover $\mathbb{P}^2$, we may do this for every point.


%since on $U_0$, we can create an adapted chart using $f$, and the same for $U_1, g$, $U_2, h$, where $f,g,h$ vanish on their respective open sets. 





\end{proof}

\begin{problem}{Question 4}

Let $V, W, S$ be real vector spaces. Prove the following:

(a) Let $\mathds{1}_V: V \to V$ denote the identity map on $V$. Prove that $\mathds{1}^\vee_V: V^\vee \to V^\vee$ is the identity map on $V^\vee$.

(b) Let $f: V \to W, g: W \to S$ be linear maps. Prove that $(g \circ f)^\vee  = f^\vee \circ g^\vee $.

\end{problem}

\begin{proof}[Solution]

(a)

We recall from section 10.3, that the dual map $\mathds{1}_V^\vee: V^\vee \to V^\vee$ is defined as, for $\alpha \in V^\vee$:

$$\mathds{1}_V^\vee(\alpha) = \alpha \circ \mathds{1}_V $$

%So fix some basis, and we consider the action of $ \alpha \circ \mathds{1}_V$ on any basis element $ e_i $ for $i \in I$, potentially uncountably infinite, where we use the result from linear algebra that assuming the axiom of choice, such a basis always exists. Additionally, since the action of a linear map is determined by its action on a basis, fix some $\alpha_j$ for $j \in I$, the same index set as for the basis for $V$.  

Fix some $v \in V$. Then, we have that for $\mathds{1}_V^\vee(\alpha) \in V^\vee$:

$$\mathds{1}_V^\vee(\alpha) (v) = \alpha_j \circ \mathds{1}_V(v) = \alpha(v)$$

%Thus, we have that $\mathds{1}_V^\vee(\alpha_j)$ sends a basis element $\alpha_j \mapsto \alpha_j$. Since the choice of basis element $\alpha_j$ was arbitrary, this implies that $\mathds{1}_V^\vee$ acts as identity on every basis element. Since a linear map is determined by its action on a basis, and this map acts as identity on each basis element, this implies that $\mathds{1}_V^\vee$ acts as identity on all of $V^\vee$.

Since this is true for all $v \in V$, this implies that $\mathds{1}_V^\vee(\alpha) = \alpha$ since, as linear functionals, they agree on all of $V$.

(b)

Again, we use the identification that, for $L: V \to W$, $L^\vee: W^\vee \to V^\vee$ via $\alpha \mapsto \alpha \circ L$ for $\alpha \in W^\vee$.

Then, let $\alpha \in S^\vee$, and consider the action of $f^\vee \circ g^\vee$. We have that:

$$f^\vee \circ g^\vee (\alpha) = f^\vee \circ (\alpha \circ g) $$

We notice that $\alpha \circ g$ is a map from $W \to \mathbb{R}$, and hence, is an element of $W^\vee$. Therefore, by the definition of $f^\vee$, we have that:

$$  f^\vee \circ (\alpha \circ g) = f^\vee(\alpha \circ g) = (\alpha \circ g) \circ f$$

Then, by the associativity of function composition, this is exactly:

$$(\alpha \circ g) \circ f = \alpha \circ (g \circ f ) = (g \circ f)^\vee$$

by definition of $(g \circ f)^\vee$. 


\end{proof}

\begin{problem}{Question 5}

Suppose a linear transformation $L: V \to \overline{V}$ is represented by the matrix $A = [a^i_j]$ relative to bases $\{ e_1,...,e_n \}$ for $V$ and $\{ \overline{e}_1,..., \overline{e}_m \}$ for $\overline{V}$. Explicitly:

$$ L(e_j) = \sum_i a^i_j \overline{e}_i$$

Let $\alpha^1,...,\alpha^n$ be the dual basis for $V^\vee$ and $\overline{\alpha}^1,...,\overline{\alpha}^m$ be the dual basis for $\overline{V}^\vee$. Prove that if:

$$ L^\vee(\overline{\alpha}^i) = \sum_j b^i_j \alpha^j$$

that $b^i_j = a^i_j$.

\end{problem}

\begin{proof}[Solution]

We use the fact that we identify the action of $L^\vee(\alpha) = \alpha \circ L$.

Using the bases fixed in the question, we consider the action of $L^\vee(\overline{\alpha}^i)(e_j)$ for $1 \leq i \leq m, 1 \leq j \leq n$. We have that by the definition of the dual, and linearity:

$$L^\vee(\overline{\alpha}^i)(e_j) = \alpha^i \circ L(e_j) = \alpha^i \sum_l a^l_j \overline{e}_l =\sum_l a^l_j \alpha^i \overline{e}_l = \sum_l a^l_j \delta^i_l = a^i_j$$

On the other hand, we have that $ L^\vee(\overline{\alpha}^i) = \sum_m b^i_m \alpha^m$. Applying the right hand side to $e_j$, we have that:

$$ \sum_m b^i_m \alpha^m(e_j) = \sum_m b^i_m \delta ^m_j = b^i_j $$

Thus, we have that:

$$ b^i_j =  \sum_m b^i_m \alpha^m(e_j) =  L^\vee(\overline{\alpha}^i)(e_j)  = a^i_j$$

Since the choice of $i$ for $\overline{\alpha}^i$ were arbitrary, and the choice of $j$ for $e_j$ were arbitrary, we may repeat for all  $1 \leq i \leq m, 1 \leq j \leq n$ and conclude that $a^i_j = b^i_j$ for all $i,j$ as desired. 

\end{proof}



\begin{problem}{Question 6}

(a) Suppose $V, W$ are vector spaces, with possibly infinte dimension, over a field $K$. Show that if $L: V \to W$ is surjective, then its dual $L^\vee: W^\vee \to V^\vee$ is injective.

(b) Suppose $V,W$ are finite-dimensional vector spaces over a field $K$. Prove the converse of (a), that is, for a linear map $L: V \to W$,  if its dual map $L^\vee: W^\vee \to V^\vee$ is injective, then $L$ is surjective.

\end{problem}

\begin{proof}[Solution]

(a)

As always, we see that $L^\vee(\alpha) = \alpha \circ L$.

Now, we recall that for linear maps, $L^\vee$ injective is equivalent to saying that $L^\vee(\alpha) = 0 \iff \alpha = 0$ for $\alpha \in W^\vee$. 

So, suppose $L^\vee(\alpha) = 0$. By definition of the dual map, this says that:

$$ \alpha \circ L(v) = 0$$ for every $v \in V$. 

Since $L$ is surjective, this implies that $\alpha(w) = 0$ for all $w \in W$. Then, we have that:

$$ (\alpha - 0^\vee)(w) = \alpha(w) - 0^\vee(w) = 0 - 0 = 0 \implies \alpha(w) = 0^\vee(w)$$

Since this is true for all $w$, this implies $\alpha$ is the $0$ covector in $W^\vee$, and thus, $L^\vee(\alpha) = 0 \implies \alpha = 0$. Because $L^\vee$ is a linear map with trivial kernel then, it is injective.

(b)

Fix a basis $\{ v_1,...,v_n \}$ for $V$, and $\{ w_1,...,w_m \}$ for $W$, and the corresponding dual bases $\{ \alpha_1,...,\alpha_n \}$, $\{ \beta_1,...,\beta_m\}$ for $V^\vee, W^\vee$ respectively.

Then, we may view $L^\vee$ as a matrix $B = [ b^i_j ]$, because it is a linear transformation of finite dimensional vector spaces. Since $L^\vee $ is injective, by the rank-nullity theorem, we have that $\dim(W^\vee) = m = \text{rank}(B) + \text{nullity}(B) =\text{rank}(B)$, since if the kernel is trivial, then $\text{nullity}(B) = 0$. 

But, by question 5, we have that for finite dimensional vector spaces, the matrix representation for the linear transformation of vector spaces and the matrix rep for the dual transformation is the same. That is, $B$ is a representation for the transformation $L: V \to W$, with $\text{rank}(B) = m = \dim(W)$. Thus, because $B$ has full row rank, $L$ is surjective.

\end{proof}

\end{document}